# APR: Adaptive Passage Retrieval for Arabic Text

This repository contains the implementation of **Adaptive Passage Retrieval (APR)**, a novel approach for Arabic text retrieval that combines a dual-encoder architecture with Attentive Relevance Scoring (ARS) for enhanced semantic matching.

## ğŸ“‹ Requirements

```bash
torch>=1.9.0
transformers>=4.20.0
numpy>=1.21.0
scann>=1.2.6
```

## ğŸš€ Quick Start

```python
from apr import DynamicDPR, AttentiveRelevanceScoring
from transformers import AutoTokenizer

# Initialize model
model_name = "asafaya/bert-mini-arabic"
model = DynamicDPR(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
model.tokenizer = tokenizer

# Example documents
documents = [
    ("doc1", "Ù‡Ø°Ø§ Ù†Øµ Ø¹Ø±Ø¨ÙŠ ÙŠØªØ­Ø¯Ø« Ø¹Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"),
    ("doc2", "Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹"),
    ("doc3", "Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠØ© ØªØ­Ø¯Ø« Ø«ÙˆØ±Ø© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ©")
]

# Create index
model.create_index(documents, batch_size=32)

# Search
query = "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
results = model.search(query, top_k=5)
print(results)
```

## ğŸ¯ Coming Soon

- **Training Scripts**: Complete training pipeline with data loaders
- **Inference Scripts**: Batch processing and evaluation utilities
- **Pre-trained Weights**: Models trained on Arabic datasets
- **Evaluation Benchmarks**: Performance on Arabic QA datasets
- **Complete Loss Implementation**: Full L_total with contrastive component

## ğŸ“š Citation

If you use this work in your research, please cite:

```bibtex
@inproceedings{bekhouche2025enhanced,
    title={Enhanced Arabic Text Retrieval with Attentive Relevance Scoring},
    author={Bekhouche, Salah Eddine and Benlamoudi, Azeddine and Bounab, Yazid and Dornaika, Fadi and Hadid, Abdenour},
    booktitle={2025 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)},
    year={2025},
    month={Aug--Sep},
    address={Istanbul, Turkey},
    organization={IEEE},
    note={Implementation available at: https://github.com/Bekhouche/APR}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
